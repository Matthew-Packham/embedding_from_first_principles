{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = open(\"names.txt\", \"r\").read().splitlines()\n",
    "names[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build the vocab ###\n",
    "\n",
    "#find all characters in our dataset\n",
    "vocab = sorted(list(set(''.join(names))))\n",
    "vocab.insert(0, \".\")\n",
    "\n",
    "#create vocab mappings\n",
    "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e | [0, 0, 0] ---> 5\n",
      "..e ---> m | [0, 0, 5] ---> 13\n",
      ".em ---> m | [0, 5, 13] ---> 13\n",
      "emm ---> a | [5, 13, 13] ---> 1\n",
      "mma ---> . | [13, 13, 1] ---> 0\n",
      "\n",
      "olivia\n",
      "... ---> o | [0, 0, 0] ---> 15\n",
      "..o ---> l | [0, 0, 15] ---> 12\n",
      ".ol ---> i | [0, 15, 12] ---> 9\n",
      "oli ---> v | [15, 12, 9] ---> 22\n",
      "liv ---> i | [12, 9, 22] ---> 9\n",
      "ivi ---> a | [9, 22, 9] ---> 1\n",
      "via ---> . | [22, 9, 1] ---> 0\n",
      "\n",
      "ava\n",
      "... ---> a | [0, 0, 0] ---> 1\n",
      "..a ---> v | [0, 0, 1] ---> 22\n",
      ".av ---> a | [0, 1, 22] ---> 1\n",
      "ava ---> . | [1, 22, 1] ---> 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_len = 3\n",
    "X, Y = [], []\n",
    "\n",
    "counter_for_show = 0\n",
    "names_for_show = 3\n",
    "for name in names:\n",
    "    #initalise context with \".\" characters (index 0)\n",
    "    context = [0] * context_len\n",
    "    \n",
    "    if counter_for_show < names_for_show:\n",
    "        print(name)\n",
    "    \n",
    "    for char in name + \".\": # add end character to the name\n",
    "        y = char_to_idx[char]\n",
    "        X.append(context)\n",
    "        Y.append(y)\n",
    "        \n",
    "        if counter_for_show < names_for_show:\n",
    "            print(f'{\"\".join(idx_to_char[idx] for idx in context)} ---> {idx_to_char[y]} | {context} ---> {y}')\n",
    "\n",
    "        #shift the context (like a rolling window)\n",
    "        context = context[1:] + [y]\n",
    "    \n",
    "    if counter_for_show < names_for_show:\n",
    "        print(end='\\n')\n",
    "    counter_for_show += 1\n",
    "\n",
    "#store as tensors\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 3]) with dtype: torch.int64\n",
      "torch.Size([228146]) with dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X.shape} with dtype: {X.dtype}\")\n",
    "print(f\"{Y.shape} with dtype: {Y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Dataset consists of 228146 examples of context length 3. Each example represents the index into our vocab. Now lets split this into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(names, context_len=3):\n",
    "    \"\"\"Function to create a dataset out of a list of names given to it\n",
    "\n",
    "    Args:\n",
    "        names (list)\n",
    "        context_len (int, optional):Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        tuple: X, Y\n",
    "    \"\"\"\n",
    "\n",
    "    X, Y = [], []\n",
    "    for name in names:\n",
    "        #initalise context with \".\" characters (index 0)\n",
    "        context = [0] * context_len\n",
    "        \n",
    "        for char in name + \".\": # add end character to the name\n",
    "            y = char_to_idx[char]\n",
    "            X.append(context)\n",
    "            Y.append(y)\n",
    "        \n",
    "            #shift the context (like a rolling window)\n",
    "            context = context[1:] + [y]\n",
    "\n",
    "    #store as tensors\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split simply by indexing\n",
    "random.shuffle(names)\n",
    "train_split = int(0.8*len(names)) #80% for train\n",
    "val_split = int(0.9*len(names)) #10% for each of val and test\n",
    "\n",
    "X_train, Y_train = create_dataset(names[:train_split])\n",
    "X_val, Y_val = create_dataset(names[train_split:val_split])\n",
    "X_test, Y_test = create_dataset(names[val_split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182751, 3]) torch.Size([182751])\n",
      "torch.Size([22687, 3]) torch.Size([22687])\n",
      "torch.Size([22708, 3]) torch.Size([22708])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_val.shape, Y_val.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network\n",
    "\n",
    "![](nn_arch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**\n",
    "\n",
    "The network takes as input the indexes of the vocab corresponding to the context. In this case the context is of length three.\n",
    "\n",
    "\n",
    "**Embedding**\n",
    "\n",
    "Next is the embedding transformation. We take the indexes and embed them into a space (of dimension we can choose, say, 2dim). So each character in our vocab goes from an integer to a vector of len(emb_dim). The best way to think of this is as an embedding matrix, C, which has dimension (len(vocab), emb_dim) i.e. each row represents a character and we use the index of that character in our vocab to index into this matrix. (e.g. \".\" character is idx=0 in vocab, which has embeding=C[0] which is a vector of len(emb_dim)).\n",
    "\n",
    "So for 1 example with context length 3 we start with a vector of len(context_length)=3, which represent the indicies in our vocab. Each index then get transformed (i.e. embedded) to a vector of len(emb_dim), say emb_dim=10, and then get concatinated. So 3 indicies tranform to 3 vectors of len(emd_dim) and then aligned together. (vector of len=30 if emd_dim=10 and context=3)\n",
    "\n",
    "**Linear Layer**\n",
    "\n",
    "Just a standard Linear Layer, with say 100 neurons (we choose), that has a tanh activation.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "The output layer is a Linear Layer, with len(vocab)=27 neurons, with softmax activation. This gives us a probility distribution over the vocab. So each of the 27 outputs represents the probability that the next character given the context is that character (soOutput[0] is the probability, given the context the next character is index 0 in our vocab which is \".\"). Note: that in training we utalise `.cross_entropy()` which internally calculates the softmax and compute the cross entropy of our ouput with the true index (given by Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice they are the roughly the same. This suggested there is still room for imrpovement. But before that lets visualise the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Loss: 26.711\n",
      "Current Loss: 2.520\n",
      "Current Loss: 2.400\n",
      "Current Loss: 2.398\n",
      "Current Loss: 2.470\n",
      "Current Loss: 2.670\n",
      "Current Loss: 2.269\n",
      "Current Loss: 2.209\n",
      "Current Loss: 2.369\n",
      "Current Loss: 2.307\n"
     ]
    }
   ],
   "source": [
    "### Train network ###\n",
    "\n",
    "## dims + embedding dims ##\n",
    "vocab_len=27\n",
    "context_len=3\n",
    "emb_dim = 2\n",
    "\n",
    "ll_neurons = 250\n",
    "mini_batch_size=64\n",
    "\n",
    "iterations = 100_000\n",
    "\n",
    "\n",
    "## Lets reverse the order, so going from large steps to small steps:\n",
    "## Parameters ##\n",
    "C = torch.randn((vocab_len, emb_dim))\n",
    "w1 = torch.randn((context_len*emb_dim, ll_neurons)) \n",
    "b1 = torch.randn((ll_neurons)) \n",
    "w2 = torch.randn((ll_neurons, vocab_len)) \n",
    "b2 = torch.randn((vocab_len)) \n",
    "parameters = [C, w1, b1, w2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    " \n",
    "for i in range(iterations):\n",
    "\n",
    "   # construct batches by randomly selecting integers. use integers to index into training set\n",
    "    ix = torch.randint(0, X_train.shape[0], (mini_batch_size,))\n",
    "\n",
    "    ## FORWARD PASS ##\n",
    "    emb = C[X_train[ix]] # (mini_batch_size, context_len, emb_dim) \n",
    "    h1 = torch.tanh(emb.view(-1, context_len*emb_dim) @ w1 + b1) #(mini_batch_size, context_len_x_emb_dim)x(context_len_x_emb_dim, ll_neurons) gives (mini_batch_size, ll_neurons)\n",
    "    logits = h1 @ w2 + b2 #(mini_batch_size, vocab_len) we want to produce p(next_char over dist given the seq) hence vocab_len\n",
    "    loss = F.cross_entropy(logits, Y_train[ix]) #softmax is applied internally\n",
    "\n",
    "    ## BACKWARDS PASS ##\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    ## UPDATE ##\n",
    "    if i <= 50_000:\n",
    "        lr=0.1\n",
    "    elif ((i>50_000) & (i<80_000)):\n",
    "        lr=0.01\n",
    "    else:\n",
    "        lr=0.001\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    \n",
    "    \n",
    "    if i % 10_000 == 0:\n",
    "        print(f\"Current Loss: {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAH5CAYAAADQowdeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKm0lEQVR4nO3de3hU1b3/8c/kNskEcoNAwAQCKCCKAlEuwQoWqqhttVArthSSWmxpbWuxPRVPi1Vq0Uqtp60V9aeBFq3VitZStSpHOArhYhC13G8hBAwGQiYkMyaTZP3+CDMyySRkJ5nMJHm/nmeeh9l77WRtJpn5ZO21v8tmjDECAACwICLUHQAAAF0PAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlkWFugMdrb6+XseOHVPv3r1ls9lC3R0AALoMY4xOnz6tgQMHKiKi5TGGbhcgjh07poyMjFB3AwCALuvIkSNKT09vsU23CxC9e/eW1HDyCQkJIe4NAABdR0VFhTIyMnyfpS3pdgHCe9kiISGBAAEAQBu0ZgoAkygBAIBlBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgWbcrZd3RjDE65fKoqrpW8fYoJTuiWeUTANDjESCa4XR79GJBsVZuLNThMpdv++AUh+ZlZ2pWVroS46JD2EMAAELHZowxoe5ER6qoqFBiYqKcTmebF9Nav7dUC1YVyF1TJ0k6+z/IO/YQFxOpx+Zkacrw1PZ1GACAMGHlM5Q5EI2s31uq3LwtcnvqZOQfHnTmuZHk9tQpN2+L1u8t7fxOAgAQYgSIszjdHi1YVdAQEs4xLmNMQ5BYsKpATrenM7oHAEDYYA7EWV4sKJa7ps5v1CEuOlK/+srFmnFRmqqqa/XEOwc1/cL+2nmsQvet2Sl3TZ1WbytW7uQhIes3AACdjRGIM4wxWrmxsMn2u6+7UBOGpGj+n9/TN5/aoolD++iigf7XhVZsKFQ3m0oCAECLCBBnnHJ5dLjM5Tf64IiJ1NcuT9evX92ljQdOas/x07rz+Q8UFfHZf5uRdLjMpXIXlzEAAD0HAeKMquraJtsG93HIHhWp7UXlvm1Ot0cHT1Q2aVsZ4HgAALorAsQZ8fb2TQfp1c7jAQDoSggQZyQ7ojU4xaGza0wePulSTW29xgxK8m1LiIvSkL7xvuc2NRSXSnJQVAro6YwxKquq0ZEyl8qqapgbhW6NP5vPsNlsmpedqSVrdvq2uWrq9Px7R3T3dRfqlMujk5XV+uk1I1Tf6D0hZ3Im5a2BHozKteiJCBBnmZWVrmVv7GkoInUmJPz61V1yxETqqXmXqaq6Vk++c0i9YxveCCJsUmx0pGaOSw9hrwGEUuPKtWcrKnNpyZqdWvbGHirXotvhEsZZEuOi9dicLNkkeQcUXDV1Wvj8Bxq1+N+6/P61euL/DjbsOLN/+Zws/rIAeigq16InI0A0MmV4qvJyxysuOrIhSDTa730eFWHTitzxupK/KIAeicq16OkIEAFMGZ6q/EXTtPhLozQoxeG3b1CKQ4P7OHTz5RmEB6AH81WubeU8SWPkq1wLdAfMgWhGYly0cicPUU52pspdHlVW16qXPUpJjmgmTAI9XHOVa1tjxYZC5WQz8RpdHwHiHGw2m5LjY5QcHxPqrgAIE97KtVadXbmW9xR0dVzCAACLAlWutYLKtegOCBAAYBGVawECBABYFqhybWtQuRbdCQECACzyVq5tztxJg/XMtycE3EflWnQXnRIgHn30UWVmZio2NlYTJkzQli1bmm27YsUK2Ww2v0dsbGxndBMAWm1WVrriYiIVKAukxMdocB//W8AjbFJcDJVr0X0EPUD87W9/08KFC3XPPfdo27ZtuvTSS3XNNdfok08+afaYhIQEffzxx77H4cOHg91NALAkUOVar0fe2qcrHnzb99xG5Vp0Q0EPEA8//LDmz5+v3NxcjRo1SsuXL5fD4dDTTz/d7DE2m01paWm+R//+/YPdTQCwrDWVa22S4qIjqVyLbieoAaKmpkYFBQWaPn36Z98wIkLTp09Xfn5+s8dVVlZq8ODBysjI0A033KAdO3Y027a6uloVFRV+DwDoLOeqXLv4S6O06e5phAd0O0G9l+jEiROqq6trMoLQv39/7d69O+AxI0aM0NNPP61LLrlETqdTy5YtU3Z2tnbs2KH09KbXDpcuXap77703KP0HgNagci16orC7C2PSpEmaO3euxowZoylTpmj16tVKTU3V448/HrD9okWL5HQ6fY8jR450co8BoIG3cm1GikPJ8TGEB3RrQR2B6Nu3ryIjI3X8+HG/7cePH1daWlqrvkZ0dLTGjh2r/fv3B9xvt9tlt9vb3VcAANB6QR2BiImJUVZWltauXevbVl9fr7Vr12rSpEmt+hp1dXX66KOPNGDAgGB1EwAAWBT0eqoLFy7UvHnzdNlll2n8+PF65JFHVFVVpdzcXEnS3Llzdd5552np0qWSpPvuu08TJ07U+eefr/Lycj300EM6fPiwvv3tbwe7qwAAoJWCHiBuvvlmlZaWavHixSopKdGYMWP0+uuv+yZWFhUVKSLis4GQU6dOaf78+SopKVFycrKysrK0ceNGjRo1KthdBQAArWQzxphQd6IjVVRUKDExUU6nUwkJCaHuDgAAXYaVz9CwuwsDAACEPwIEAACwjAABAAAsI0AAAADLCBAAAMAyAgQAALCMAAEAACwjQAAAAMsIEAAAwLKgl7IGwoUxRqdcHlVV1yreHqVkRzTLLQNAGxEg0O053R69WFCslRsLdbjM5ds+OMWhedmZmpWVrsS46BD2EAC6HtbCQLe2fm+pFqwqkLumTpJkJC276RIlxEbrO38pkCTFxUTqsTlZmjI8NYQ9BYDQs/IZSoBAt7V+b6ly87bISDr7p7y3PUo2m1Txaa0kyWaTbJLycscTIgD0aCymhR7P6fZowaqCJuFBkk5X1/rCg87sN5IWrCqQ0+3p1H4CQFdFgEC39GJBsdw1dU3Cg9RwCeOJb2b5bTNGctfUafW24k7qIQB0bQQIdDvGGK3cWNimY1dsKFQ3u6oHAEFBgEC3c8rl0eEyl6zGACPpcJlL5S4uYwDAuRAg0O1UVdeeu1ELKtt5PAD0BAQIdDvx9vaVN+nVzuMBoCcgQKDbSXZEa3CKQ1ZrTNrUUFwqyUFRKQA4FwIEuh2bzaZ52ZltOjZncmaPLm9tjFFZVY2OlLlUVlXDhFIAzWKsFt3SrKx0LXtjj9yewLdyNhZhk2KjIzVzXHrwOxeGKPcNwCpGINAtJcZF67E5WbKpodLk2WIiI1R1prS1ztq/fE5Wj/yQXL+3VJOWrtWSNTtVdFZ4kKSiMpeWrNmpSUvXav3e0hD1EEA4IkCg25oyPFV5ueMVFx0pm6SoCJvO79dL4wYna9/x0w3hQlJcdKRW5I7XlT2wjLW33LfbU9dQtbPRfu82t6dOuXlbCBEAfFgLA92e0+3R6m3FenffCf3x6+OUf/Ck7vjb+0qOi1HO5Ibh+YTYnjfy4HR7NGnp2lZf5rHZGsJW/qJpPXKkBugJrHyGMgcC3V5iXLRyJw9RTnamyl0eXdCvl9b/5ColOaJ79IRJX7nvs7bZbNJtnxuqW8YP0oCkWJ2orNGzm4v06Nv7/cp9504eErJ+AwgPBAj0GDabTcnxMUqOjwl1V0KuuXLfP7tmpGaPz9CSNTu1tfCU+vW2a1i/Xn5tVmwoVE52z75bBQABAuiRvOW+zxYfE6ncyZla/MoOvbjtqKSGSZTvHT7la3N2uW+CGNCzMYkS6IEClfs+v18v2aMjtWH/iXMeT7lvAAQIoAcKVO77U099q4+n3DcAAgTQAwUq9114skrumjpNPr9vs8dR7huAFwEC6IEClfuurq3X8vUHtOjakZo57jwNSnFobEaSvnZZhl+7nl7uG0ADxiGBHipQue/f/+8+1dYbLfzCcPXrHatPTn+qZzcXSaLcNwB/FJICejBvJUojtVhMymZruHzRUyt2Aj2Flc9QLmEAPVjjct+NL0xQ7htAc7iEAfRwU4anKn/RNK3eVqwVG/xX4xyU4ujR5b4BNI9LGAB8jDEqd3lUWV2rXvaoHl/uG+hpWAsDQJtQ7htAazEHAgAAWEaAAAAAlhEgAACAZcyBAAB0CcYYnXJ5VFVdq3h7lJKZ5BtSBAgA7cYbO4LJ6fboxYJirdzof5vx4BSH5mU33GacGMdtxp2N2zgBtBlv7Ai29XtLtWBVgdw1dZKksz+wvBE1LiZSj83J0hQKnbWblc9QAgSANuGNHcFmtdR6Xu54ftbaiVLWAILK+8bu9tQ1vLk32u/d5vbUKTdvi9bvLe38TqJLc7o9WrCq4JzhQWf2G0kLVhXI6fZ0Rvcg5kAAsKjxG/tzt03UnpLTkqSvjDtPtXVGqzYd1sNv7m1447c1vLHnL5qmxLho5kugVV4sKJa7ps4XTqcMT9Xtnz9fI/r3Vl290baiU7r3nztVdObSmTGSu6ZOq7cVK3fykNB1vAchQACwpPEbu9SwNPjzW4/oxj9u0Oj0RC2dOVrHyt16busR3xv7M5sPKzYqkvkSOCdjjFZuLPTbFhcTqf/3ziHtLqlQfEyUfvyF4Xr8m1m67vfv+I1QrNhQqJzsTEJpJyBAAGi1QG/skvRxuVv3rdkpSTp4okoj03rr1iuG6LmtR3xtHnp9j84MSPgpKnNpyZqdWvbGHuZLQJJ0yuXxC5mS9Pp/Svye/9ffP9D7i6/WBf16ae/xSkkNlzEOl7lU7vJQjr0TECAAtFqgN3ZJev9Iud/zbUXl+vbnhirCJtUb/zkSgeZLSJ/Nl2AiHKqqa5tsy+zj0MIvDNeYjGQlx0cr4swIw8CkOF+A8KqsriVAdAImUQJotUBv7B2FiXDwirc3/dv2qXmXK8kRo7tWf6gbH92oGx/dIEmKiWz6MdYrwPHoePwvA2i1QG/skjQmI8nv+diMJBWeqFJ9o+GG+JhI3f+V0br6ov6q/LRWj//fQX1hVH/tPFah+9bsZCIcJEnJjmgNTnGoqMwlIynJEa1h/XrprtUfamvhKUnSZYOTmxxnkzQoxaEkB3NpOgMjEABazfvG3ngew8CkOP38+gs1tG+8vnzpQM3LzlTehsImx//8i6N0WWayvr3yPc15arMuz0zRRQOb3mu+YkOhulmJGlhgs9k0LzvT99zp9qisqka3jB+kwX0cmjSsj37+xVEBj82ZzATKzkKAANBqjd/YvVZvK1ZsdKRevn2y7rvhIuVtKNSzW4r82sTHRGrWuHTd/69d2njgpPYer9RPX/hAkRH+b/ZnT4RDzzUrK11xMZGy2Roub/3gr9s0+rxEvXHHlVr8xVFa+uouv/YRtoY7NWaOSw9Rj3seLmEAsGRWVrqWvbGnoYjUmUGC2jqj+9bs0M9f/k+zxw3q41BMVIQ+OGvC5enqWh0srQrYnolwPVtiXLQem5Ol3Lwtkk3asP+kvvC7//Nrk3nXvyQ1VKKUpOVzsrgVuBMxAgHAEu8bu02fvXEHQ8WZYWsuZfRcU4anKi93vOKiIxt+3hrt926Li47UitzxupK7dzoVAQKAZWe/sQcS6M2+6KRLNbX1WvGt8Vp85vp1b3uUhvSND/g1rv/Duxq35E1NfWidnn73EHdm9FBThqcqf9E0Lf7SKA1KcfjtG5Ti0OIvjdKmu6cRHkKAxbQAtJnT7dHqbcVasaFpdcnZ4zP08Jt75an77C1m6czR+srY8/T27k/08Jt79eMvDNfnLuir5987oiVrdgX6FizMBR9jjMpdHlVW16qXPUpJlEHvcFY+Q5kDAaDNEuOilTt5iHKyM5u8sedtKFRtnf/fJ3HRkYqNjtS1owfo2tEDJEk7jzpV7alv9ntQaApeNptNyfExzI0JEwQIAO3W+I29uZLXv3j5P8pIcWhPyWn97s29io2O0L9++DkVnmxa3bKxQAtzAQgdAgSADtdcyetBfRxKiI1SdKRN/RLs+tG0CyRJb+78bJ2Day9O04+mX6DMPvFy19Rpx7EKzf/ze767Pig0BYQHAgSADtdSyesBSXHK7BOvL4zqr4+OOnXT8nydOlPzIbW3Xb+/ZaweeG23/r2jRPExUbp8SEqTuz1YcREIPQIEgA7XXMnrHccq9J+jTl/p6sb69bYrOjJCr/+nREfL3ZKkPcdP+7VhxUUgPHAbJ4AO11zJa0mqqa1XRETgkYNdH1fo3X0n9Podn9OjXx+n2ZdnKCEucBipDOLCXgDOjQABoMM1V/JakopPuTUmI0npyXFKdkT7XZ6oN9KcpzYrJ2+r9n9yWvOyM/W/d05VenJck6/DiotAaBEgAATF2WsZnO3Jdw6qvt7ozR9P0fuLr9Z5SU3DQcHhU/rdW/t0/e/fkaeuXtdclObbZ1NDnQlWXERrGWNUVlWjI2WusK1u2hX62BgRHkBQNF7LwPt+eOhElWY+tjHgMWMykpQ9rI/e2XdCJyurNWZQklLiY3Tgk0q/dqy4iNZwuj16saBYKzc2LXQ2LztTs7LSQ347cFfoY3OoRAkgqNbvLdWCVQVy19RJ+qwwlNQwmnD282GpvbT4ixfqovMS1dsepeJyt1ZuLNSf8w9LalhxMTY6kjoQOKdz/dxJoa9uGo59tPIZ2imXMB599FFlZmYqNjZWEyZM0JYtW1ps/8ILL2jkyJGKjY3V6NGj9eqrr3ZGNwEEwbnWMvjGhEG+hbkOlFZqXt5WXfartzTiF69r2m/X+8IDKy6itdbvLVVu3paG2iHy/2DWmedGn1U3Xb+3lD62QdBHIP72t79p7ty5Wr58uSZMmKBHHnlEL7zwgvbs2aN+/fo1ab9x40ZdeeWVWrp0qb74xS/q2Wef1YMPPqht27bp4osvPuf3YwQC6HjGGJ1yeVRVXat4e9SZyY/WLyE0t5ZBa/8SWz4ni0WT0CKn26NJS9f6LTffEputocR6Z45qhXMfrXyGBj1ATJgwQZdffrn++Mc/SpLq6+uVkZGhH/zgB7rrrruatL/55ptVVVWlNWvW+LZNnDhRY8aM0fLly5u0r66uVnV1te95RUWFMjIyCBBAB+jM67MtLcyVM7nheyXEtvy9OirooOt6+t1DWrJmp18IjYmM0KLrRupLlw5Ub3uUPjzq1JI1O/VhsVNSQ0hd/KVRnVbdNFAfbTZpwZRhumX8IKX2tuvQiSr9fu0+vfafkk7tY9gsplVTU6OCggItWrTIty0iIkLTp09Xfn5+wGPy8/O1cOFCv23XXHONXn755YDtly5dqnvvvbfD+gyggXdU4OmcyzUvO9Ov8FNRmUtL1uzUsjf2dNj12ZYW5jpXCOjKE9HQcZpbg2XRdSN17cUD9JPnP1BxuVvfnTJUf/7WeE15aJ1vmfjOqm7aXB+/N/V8fWXsefrvlz7SoZNVmjCkjx65eYzKqrZo86GyTu1jawV1DsSJEydUV1en/v37+23v37+/SkpKAh5TUlJiqf2iRYvkdDp9jyNHjnRM54Ee7Ozrs4EE8/qsd2GujBSHkuNjzvlmuX5vqSYtXasla3aqqNH6G96gM2np2rC8hoyO5V2D5ey/7OOiI/WNCYP161d3ad3eUu3/pFJ3vfiRPvXU6+bLMyT5VzcNRR9jIiP0/auG6b/+/oH+b98JHSlz6+8FxXpp+1F9fcIgvz4eOlEVNrd4dvnbOO12u+x2e6i7AXQbTrdHC1YVNISEc7xPhXqFTG/QCTQJTWIp8J4m0Bosg/s4FBMVoYLDp3zbauuNPigu1/n9evm1rayuDXp59Ob66IiJ0l9uneC3PToyQjuPOf22ff6368NmZC2oAaJv376KjIzU8ePH/bYfP35caWlpAY9JS0uz1B5Ax3qxoFjumrqAH8iSdNWIfnpyXpbe3XdCOXlbQ7ZCZlcKOugcza3B0lqdUd00UB+92761YqtKKj7121dTW9+kfTAuIbZFUC9hxMTEKCsrS2vXrvVtq6+v19q1azVp0qSAx0yaNMmvvSS9+eabzbYH0HG812eb+zz+8qUD9ftbxmj/J5U6WFrlt2/FhsJOHVr1BR0jpcTHaOt/T9P3pg7z7R83KFl7f3Wtsof1kSS/oIPuKdAaLIdPulRdW6eswcm+bVERNl2Snqh9xxsKlHVmddNAfdx3/LSqPXUamBSnwyddfo+PnZ82+Rrhcotn0OtALFy4UE8++aRWrlypXbt2acGCBaqqqlJubq4kae7cuX6TLH/0ox/p9ddf129/+1vt3r1bv/zlL/Xee+/p9ttvD3ZXgR7Pe302kG9OHKxf3Xixvr3yvSbXijvzGrLUdCJaWVWNfvr3D3XH9OEafV6i4mMi9bubL9Wf8wu18cBJv2M7O+ig8wRag8XtqdMzm4p093UXasrwVJ3fr5cemDVacdGR+tt7Rb52nVXdNFAfq2rq9MQ7B/WLL47SrHHnaVCKQxcNTGi4TDHuvGa/ljENv3sLVhX4JoN2pqCP19x8880qLS3V4sWLVVJSojFjxuj111/3TZQsKipSRMRnOSY7O1vPPvusfv7zn+vuu+/WBRdcoJdffrlVNSAAtE+g67MRNptmj89QXHSkTlXVaHR6YrPHd8Y1ZClw0Fm3p1TPbS3SI7PH6KNip1w1dfrN63v82rAUePc3Kytdy97Y41dj4cHXd8tmkx7+2qXqdeY2zrlPb1GFu9ZX3XTmuPSQ9vG3b+xVWVWNvjf1fGWkOFTxqUc7jjp14cAEJcZF6+kNhb7jX/3hFXpj53E98ta+kF1ClDppEuXtt9/e7AjCunXrmmy76aabdNNNNwW5VwAac8RENtk2KMUhm2w65fJo44GTmji0jy4amKCdxyqatI0PcHwwBAo6knT/v3bpjR9fqetGD9CX/vCuauqaXj+WOi/ooPMFWoOlurZe9/5zp+79506/tqGqbtrcOjF5GwqVd1ZQkKR3f3ZVq75mKG7xZDVOAM1yxESqX4Jd+QdPaNZjG3X5kBSdOF2tqIjQvnU0N1lucB+H+ifEKsImpac0XeXTi6XAu7cpw1OVlztecdGRDWXSG+33bouLjtSK3PEhqW56rj5a0dmXEL0IEAB8XDX+dR8G93EowmZT6elqHTpRpVue2KTPj+wnV03gEYCqmsB1IzpaoIlo0ZE2PXLzGK358JgefnOvHph5ifo0GmVgKfCe41xrsCz+0ihtuntaSEujt9THtqhsZmQuWIjhAHzOdRvcwRNVuuXJzfr3HZ/T+CEpTfZ31l/23oloS86qjvmTq0eod2y0fvnKTlXV1GrqiH76zVcv0a0r3/M7lqXAe472VDftLGf38dCJKn3+t+v99tfXq0lfoyID/+3f2SNrjEAA8PH+Ze91+KRLNbX1freJlVZ+qpq6em05U17Xq7P/sp+Vla64mEjZbNLEoSn61hVD9OO/bVdlda2MkRY+v12XD0nRnDOV/CJsDQtydeZkOYQHq9VNQ8Fms2lI3/gmI2tlVdVK7f1ZscRe9ihlJPuPVoRqZI0AAcDH+5e99w3MVVOn5987oruvu1CThvXR8P699NubLlV9o7sgber8v+y9E9FskjYfKtMF//2a3jur2mDxKbcu+eUbWrW5iKXA0SUEusVz44GTmjn2PF2emawR/Xvrt1+7VHUBbkMOxcgaAQKAn1lZ6YqJ+uyt4dev7tKWQ2V6at5leubbE7S18JT+c9S/vG5MVERI/rLvCpPlACvOHlmTpD+tO6DNh8r0VM7lejr3cr2xo0RFJz8r4hbKkbWgL+fd2awsRQqgKafbo/H3v6XqACV0m2OPitCW/54esr/uO2IpcCBc+K3x0sIntM3WEJA7MhyHzXLeALqeFwuK/ervpyfH6d2ffb5Ju00HT2r2E5skNdTrD0UhG6+uMFkOaC3vyNqCVQVyn7mz6ewc4f2JjouO1PI5WSEbWSNAAPBpXCJako6Vu3X5r97yPU/tbdeqb0/Q5kaTKENRyKYx72Q5ikShq/Pe4hloZG1QmIysESAA+AQqEV1vpNLKakkNlyqemJulbUWn9Mhbe31tKBENdLxwH1kjQADwaa5EtNdvvnqJ4u1RmvP/Nge8NkuJaKDjhevIGgECgE9LhaRu//z5uvKCVN3w6IZmK06GokS0MUanXB5VVdcq3h6l5DD56wzo7ggQAHy8haSKylx+k7ZmXJymH37+AuXkbVFRgOW+bWq4LtuZhWxq6+q1p+S0vvfMtiZ3XszLbrg+TM0HIHioAwHAJ1Ahm+H9e+nhr12q5esPaN/xSqX2siu1l73Jh3NnFrJZv7dU24rKtflQWZNAU1Tm0pI1OzVp6Vq/CpoAOhYBAoCfxoVsLklPkiMmSj+cdoG2/ny67/H4N7MkdX4hG+898vVnJmE0nophzjzcnjrl5m0hRABBQiEpAE2EspBNS5xujyYtXSu3p05/nT9Ruz6uUHVtvWZfniFPXb2e2VykR97a59e/uOhI5S+axuUMoBWsfIYyAgGgiXAtEf1iQbHcNXW+UDMrK13umjrd+OgGLX1tt374+Qt0xfl9fe2Nkdw1dVq9rbhT+gf0JAQIAAF5C9ks/tIoDUrxX/1vUIpDi780SpvuntZp4SFQkavdH5/W/6zdp8KTLq3edlQfHnVq8vl9mhy7YkOhutlgKxBy3IUBoFnhVMgmUJGr3SUVfs9LT3+qPr3sftsocgUEBwECwDmFQyGbQEWuauv8RxWMaZjUGQhFroCOxSUMAF1CS0WuWiMURa6A7owAAaBL8Ba5snrhxKaG4lKdWeQKCDZjjMqqanSkzKWyqpqQzPEhQADoEgIVuWqtzixyBQST0+3R0+8e0tSH1mnckjd1tNytl98/qqkPrdPT7x6S0+3ptL5QBwJAl3F2HYjWvHNF2KRY6kCgm1i/t1QLVhXIfWYtGqOGic61dfVyndkWFxOpx+ZkaUob746iDgSAbikxLlqPzclqqENxjgEF7/7lc7IID+jyvMXd3J46X7VVqSFUV9XUhaQCKwECQJcSrkWugGBxuj1asKogYGXY526bqMVfHOV7bkxDkFiwqiDolzMIEAC6nHArcgUEU+MKrOfSWRVYua8JQJcUTkWugGAJVIG1tVZsKFROdvAmEBMgAHRp4VDkCgiWQBVYW6MzKrByCQMAgDAVqAKrFZXtPL4lBAgAAMJUOFdgJUAA6BLCofIe0NnCuQIrcyAAhDWn26MXC4q1cmOh37XgwSkOzcvO1KysdOo8oNvyVmBdsman5WODXYGVSpQAwlagynte3rfF9lbeA8JdZ1ZgpRIlgC6vucp7XqGovAeEQrhWYCVAAAg7LVXea6wzK+8BoRKOFVgJEADCjrfy3lUj+unDe65WxJl3y1EDElT4wPX62YwRvrYPzBqth782plMq73U0JobCinCrwMokSgBh5ezKe1sPlSneHqWLBibqo6NOTRiaopOV1Zo4tI+v/YQhfbR8/QFJwa+811GYGIq2CqcKrIxAAAgr3sp7RtLp6lrtPFbhCwwTh/bRU+8e0qiBCXLERKp/gl1D+sZr88GTfpX3wtn6vaWatHStlqzZqaJGFQaLylxasmanJi1dy5wOtMhbgTUjxaHk+JiQhGYCBICw0rjy3uZDJzVxaIok6fLMFP17R4kOfFKpyzNTNGFIH5U4P1Xhyc8+iINZea+9mBiK7oQAASCsNK68t+ngSV2emaJRAxJUW1evA6VV2nSwTBOHpmji0BRtPnTSr30wK++1BxND0d2E528agB7LW3mv6MxljC2FDfMgbr1iiDYfKpPUECoWTB2mhLho/b93DkpqmIE+KMiV99rDtyTzmefP3TZRuz6uUHVtvWZfniFPXb2e2VykR97aJ8l/SebcyUNC13GgGYxAAAgr3sp7XhXuWu0uqdANYwZq08GG0YbNh8p00cBEDUvtpc0Hy3xtg115r62aW5J5Vla63DV1uvHRDVr62m798PMX6Irz+/q1WbGhkLszEJYIEADCzqysdMXFRPqK4mw+WKaoyAhfgHC6Pdr/yWl9UvGpDp6oUoStoSLlzHHpIex1886eGHq23R+f1v+s3afCky6t3nZUHx51avL5n91h0lUmhnYV3DbbsbiEASDseCvv5eZtkWzSfWt26r5GawFc9/t3JXVu5b22am5J5t0lFX7PS09/qj697E3aVVbXKjk+Jih96wm4bTY4GIEAEJbCsfJeWzW3JHNtnf9fwMbIVzTrbOE6MbQr4LbZ4CFAAAhb4VZ5r63CeUnm7ozbZoOLWAsgrIVT5b22Cuclmbsrq7fNytZw22xbVrDsqRiBAHqgrjiZLBwq77VH44mh5xLuE0PDne+22TM/2jPHnaf3f/EFxUT6f+w98c0sPfy1S/1um0XrMAIB9CBMJgudxhNDZz+xqUmb2/5SIKlrTAwNZ4Fum/3Xhx/rl1+6SNNH9dOrH5VIkvrEx+iqkf0096ktvnZdZT2VcMAIBNBDMJks9LrTxNBwFui22eraev1j+zHdlJXh23bj2PN0rNyt/DO3B3PbrDUECKAHYDJZ+OguE0PDWXO3zT63tUifu6Cv+ic03Cr71ax0/b2g6SWLcF5PJZxwCQPo5phMFn66w8TQcNbcbbM7jlVo18enNWtcuv5vX6mG9++tb63Y2qQdt822Dv9LQDfnnUz219smanfJadXXG83KSldNbb1++8Ye/WP7Md13w0W6dvQAnThdrV++skPr95ayBkMn8E4MpUhUx2q8nsrZ/ra1SLlXDFH/hFht2H9CHzs/9e0L9/VUwg2XMIBurPFkslnjzlOZq0Y3/PFdrcwv1K9uvFh/+sY4FRw+pS/+/h29s++EHr55jGKjI1iDAV1W4/VUzvaP7cc0IDFWs8dn6Pn3jjTZz22zrUeAALqxxpPJdn18Wn/83/0qPOnSn97er+raepW5avTc1iMqPOnS79fuU0p8jEamJTCZDF1ac7fNnq6u1Wv/KZGruk5v7Dju285ts9YRIIBurPFksrPXXqg30ilXjfaUnPZtK62sliT16dUwpM5kMnRV3ttmbVKTEJGWEKuXtx9VTV29JG6bbSsCBNCNNZ5M1njthYZt9U22RZx5R2UyGbqyxrfNJsZF6ZqL+mvi0D76S/5hbpttJ94dgG7s7MlkVrEGA7oD722zq7cVa8bFaYq3R+mB13br4IkqDU5xKGdyQwG1hFh+1q0iQADdGGswAJ/dNmuMUbnLo7mTBut7U4dx22w7cQkD6Oa8k8mssEdFMJkM3U5XX08l3NhMN7tPq6KiQomJiXI6nUpISAh1d4Cw4K1Eea5iUjZbwzVhrgcDPZOVz1BGIIAegDUYAHQ05kAAPcTZk8lWbPBfjXMQk8kAWMQlDKAH8k4mYw0GAGez8hnKCATQA7EGA4D2Yg4EAACwLKgBoqysTN/4xjeUkJCgpKQk3XrrraqsrGzxmKlTp8pms/k9vvvd7wazmwAAwKKgXsL4xje+oY8//lhvvvmmPB6PcnNzddttt+nZZ59t8bj58+frvvvu8z13OBzB7CYAdDhjjE65PKqqrlW8PUrJzDNBNxO0ALFr1y69/vrr2rp1qy677DJJ0h/+8Addd911WrZsmQYOHNjssQ6HQ2lpacHqGgAEjdPt0YsFxVq50f9Ol8EpDs3LbrjThQWb0B0E7RJGfn6+kpKSfOFBkqZPn66IiAht3ry5xWOfeeYZ9e3bVxdffLEWLVokl6v5Ov7V1dWqqKjwewBAKKzfW6pJS9dqyZqdTdYfKSpzacmanZq0dK3W7y0NUQ+BjhO0AFFSUqJ+/fr5bYuKilJKSopKSkqaPe7rX/+6Vq1apbfffluLFi3SX/7yF82ZM6fZ9kuXLlViYqLvkZGR0WHnAACt5a326fbUNVT8bLQ/KtImI8ntqVNu3hZCBLo8y5cw7rrrLj344IMtttm1a1ebO3Tbbbf5/j169GgNGDBA06ZN04EDBzRs2LAm7RctWqSFCxf6nldUVBAiAHQqp9ujBasK/EqFP3fbRO0pOa26eqMbx56nPSWndcuTmxr226QFqwqUv2galzPQZVkOEHfeeadycnJabDN06FClpaXpk08+8dteW1ursrIyS/MbJkyYIEnav39/wABht9tlt9tb/fUAoKO9WFAsd01dk1GHWVnpWrXpsL762Ea/7cZI7po6rd5WrNzJQzqvo0AHshwgUlNTlZp67jr5kyZNUnl5uQoKCpSVlSVJ+t///V/V19f7QkFrbN++XZI0YMAAq10FgKAzxmjlxsKA+wpPVOmB13Y3e+yKDYXKyWbZdHRNQZsDceGFF2rGjBmaP3++tmzZog0bNuj222/X7NmzfXdgHD16VCNHjtSWLVskSQcOHNCSJUtUUFCgwsJCvfLKK5o7d66uvPJKXXLJJcHqKgC02SmXR4fLXE1GHyTpo6POZo8zkg6XuVTu8gStb0AwBbWQ1DPPPKORI0dq2rRpuu6663TFFVfoiSee8O33eDzas2eP7y6LmJgYvfXWW7r66qs1cuRI3XnnnZo1a5b++c9/BrObANBmVdW1ze5z19Sd8/jKFo4HwllQC0mlpKS0WDQqMzNTZ6/llZGRofXr1wezSwDQoeLt7Xsb7dXO44FQYS0MAGiHZEe0Bqc4ZHUWg00NxaWSHNyFga6JAAEA7WCz2TQvO7NNx+ZMZgIlui7GzgCgnWZlpWvZG3saikiduSo7+4lNzbaPsEmx0ZGaOS69k3oIdDxGIACgnRLjovXYnCzZJJ1rQMG7f/mcLIpIoUsjQABAB5gyPFV5ueMVFx3ZECQa7fdui4uO1Irc8bpy+Lnr6QDhjEsYANBBpgxPVf6iaVq9rVgrNvivxjkoxaGcyQ2rcSbEMvKArs9mzr6PshuoqKhQYmKinE6nEhISQt0dAD2UMUblLo8qq2vVyx6lJEc0EyYR9qx8hjICAQBBYLPZlBwfo+T4mFB3BQgK5kAAAADLGIEA0CGMMTrl8qiqulbx9iglM2QPdGsECADt4nR79GJBsVZu9J80ODjFoXnZDZMGuV0R6H6YRAmgzdbvLdWCVQW+RaPOfjPxjj3ExUTqsTlZmsJti0DYs/IZyhwIAG2yfm+pcvO2NFRflJosZ+3d5vbUKTdvi9bvLe38TgIIGgIEAMucbo8WrCpoCAnnGMM0piFILFhVIKfb0xndA9AJCBAALHuxoFjumoZ1H24Zn6HNd09rUsL5yblZ+s1XL5HUECLcNXVava04BL0FEAwECACWGGO0cmOh7/m/PvpYSY5oTRrax7ctMS5aVw5P1cvvH/U7dsWGQnWzaVdAj0WAAGDJKZdHh8tcvjkPFe5ard9TqhvGnOdrc93oNJ2q8ij/4EnfNiPpcJlL5S4uYwDdAQECgCVV1bVNtr28/aiuvThNMZENbyk3jjlP//zwWMD5EZUBjgfQ9RAgAFgSb29aPmbtrk8km3TVyH4akBiryzNTmly+8OoV4HgAXQ+/yQAsSXZEa3CKQ0VnXcaorq3Xv/9TohvHDlRmH4cOnqjSjmMVfsfZ1LAiZZKDolJAd8AIBABLbDab5mVnNtn+8vaj+vyIfvraZRl6eXvg0YecyZmUtwa6CQIEAMtmZaUrLibS79bNjQdOqtzt0bB+vfSPRgEiwtZQkXLmuPRO7imAYOESBgDLEuOi9dicLOXmbZFsZ4pFGWnCr9c2aesNGcvnZLEmBtCNMAIBoE2mDE9VXu54xUVHyqbP1r7w8m6Li47UitzxupK1MIBuhREIAG02ZXiq8hdN0+ptxVqxwX81zkEpDuVMbliNMyGWkQegu2E1TgAdwhijcpdHldW16mWPUpIjmgmTQBdj5TOUEQgAHcJmsyk5PkbJ8TGh7gqATsAcCAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWUQcCACwwxuiUy6Oq6lrF26OUTMEs9FAECABoBafboxcLirVyo3/J7sEpDs3LbijZzWJh6EkoZQ0A57B+b6kWrCqQu6ZOkvTX2yZq57EK3bdmp28RsbiYSD02J0tTWDQMXZiVz1DmQABAC9bvLVVu3ha5PXUykhr/xeXd5vbUKTdvi9bvLe38TgIhQIAAgGY43R4tWFXQEBLOMVZrTEOQWLCqQE63pzO6B4QUAQIAmvFiQbHcNXXnDA9exkjumjqt3lYc3I4BYYAAAQABGGO0cmNhm45dsaFQ3Wx6GdAEAQIAAjjl8uhwmavJnIdzMZIOl7lU7uIyBro3AgQABFBVXduu4yvbeTwQ7ggQABBAvL19ZXJ6tfN4INwRIAAggGRHtAanOGS1xqRNDcWlkhwUlUL3RoAAgABsNpvmZWe26dicyZmUt0a3R4AAgGbMykpXXEykWpsFImwNFSlnjksPbseAMECAAIBmJMZF67E5WbJJfiFi9hObdN+anX5tvfuXz8liTQz0CAQIAGjBlOGpyssdr7joyIYg0Wi/d1tcdKRW5I7XlayFgR6CacIAcA5Thqcqf9E0rd5WrBUb/FfjHJTiUM7khtU4E2IZeUDPwWqcAGCBMUblLo8qq2vVyx6lJEc0EybRbVj5DGUEAgAssNlsSo6PUXJ8TKi7AoQUcyAAAIBlBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBlBAgAAGAZAQIAAFhGgAAAAJYFLUDcf//9ys7OlsPhUFJSUquOMcZo8eLFGjBggOLi4jR9+nTt27cvWF0EAABtFLQAUVNTo5tuukkLFixo9TG/+c1v9Pvf/17Lly/X5s2bFR8fr2uuuUaffvppsLoJAADawGaMMcH8BitWrNAdd9yh8vLyFtsZYzRw4EDdeeed+slPfiJJcjqd6t+/v1asWKHZs2e36vtVVFQoMTFRTqdTCQkJ7e0+AAA9hpXP0LCZA3Ho0CGVlJRo+vTpvm2JiYmaMGGC8vPzmz2uurpaFRUVfg8AABBcYRMgSkpKJEn9+/f3296/f3/fvkCWLl2qxMRE3yMjIyOo/QQAABYDxF133SWbzdbiY/fu3cHqa0CLFi2S0+n0PY4cOdKp3x8AgJ4oykrjO++8Uzk5OS22GTp0aJs6kpaWJkk6fvy4BgwY4Nt+/PhxjRkzptnj7Ha77HZ7m74nAABoG0sBIjU1VampqUHpyJAhQ5SWlqa1a9f6AkNFRYU2b95s6U4OAAAQfEGbA1FUVKTt27erqKhIdXV12r59u7Zv367Kykpfm5EjR+qll16SJNlsNt1xxx361a9+pVdeeUUfffSR5s6dq4EDB+rGG28MVjcBAEAbWBqBsGLx4sVauXKl7/nYsWMlSW+//bamTp0qSdqzZ4+cTqevzX/913+pqqpKt912m8rLy3XFFVfo9ddfV2xsbLC6CQAA2iDodSA6G3UgAABomy5ZBwIAAHQdBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBlBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBlBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBlBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBlBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBlBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlgUtQNx///3Kzs6Ww+FQUlJSq47JycmRzWbze8yYMSNYXQQAAG0UFawvXFNTo5tuukmTJk3SU0891erjZsyYoby8PN9zu90ejO4BAIB2CFqAuPfeeyVJK1assHSc3W5XWlpaEHoEAAA6StjNgVi3bp369eunESNGaMGCBTp58mSL7aurq1VRUeH3AAAAwRVWAWLGjBn685//rLVr1+rBBx/U+vXrde2116qurq7ZY5YuXarExETfIyMjoxN7DABAz2QpQNx1111NJjk2fuzevbvNnZk9e7a+/OUva/To0brxxhu1Zs0abd26VevWrWv2mEWLFsnpdPoeR44cafP3BwAArWNpDsSdd96pnJycFtsMHTq0Pf1p8rX69u2r/fv3a9q0aQHb2O12JloCANDJLAWI1NRUpaamBqsvTRQXF+vkyZMaMGBAp31PAABwbkGbA1FUVKTt27erqKhIdXV12r59u7Zv367Kykpfm5EjR+qll16SJFVWVuqnP/2pNm3apMLCQq1du1Y33HCDzj//fF1zzTXB6iYAAGiDoN3GuXjxYq1cudL3fOzYsZKkt99+W1OnTpUk7dmzR06nU5IUGRmpDz/8UCtXrlR5ebkGDhyoq6++WkuWLOESBQAAYcZmjDGh7kRHqqioUGJiopxOpxISEkLdHQAAugwrn6FhdRsnAADoGggQAADAMgIEAACwjAABAAAsI0AAAADLCBAAAMAyAgQAALCMAAEAACwjQAAAAMsIEAAAwDICBAAAsIwAAQAALAvaapzo2YwxOuXyqKq6VvH2KCU7omWz2ULdLQBAByFAoEM53R69WFCslRsLdbjM5ds+OMWhedmZmpWVrsS46BD2EADQEQgQ6DDr95ZqwaoCuWvqfNt+/ZXRum50mpIcMbruf97Rsjf26LE5WZoyPDWEPQUAtBcBAh1i/d5S5eZtkZFkzmybOjxVX81K1+wnNulImUtlrhrVG6PcvC3Kyx1PiACALoxJlGg3p9ujBasKGsKD+Wz7oD4OfXL6U20rOqXSymrV1RsZ0xAwFqwqkNPtCVWXAQDtRIBAu71YUCx3TZ1feFh20yW674aLlZ7sUOED1+vdn13l22eM5K6p0+ptxSHoLQCgI3AJA+1ijNHKjYVNtt/7yk4dPunSLeMH6YY/blDd2enijBUbCpWTncndGQDQBREg0C6nXB6/uy28TlfXqqq6VvXGqLSyusl+I+lwmUvlLo+S42M6oacAgI7EJQy0S1V1bbuOr2zn8QCA0CBAoF3i7e0bxOrVzuMBAKFBgEC7JDuiNTjFIauzGGxqKC6V5KCoFAB0RQQItIvNZtO87Mw2HZszmQmUANBVESDQbrOy0hUXE6nWZoEImxQXE6mZ49KD2zEAQNAQINBuiXHRemxOlmySX4h4ekOhrnjwbb+23v3L52SxJgYAdGEECHSIKcNTlZc7XnHRkQ1BotF+77a46EityB2vKyljDQBdGlPg0WGmDE9V/qJpWr2tWCs2+K/GOSjFoZzJDatxJsQy8gAAXZ3NmAAlAruwiooKJSYmyul0KiEhIdTd6bGMMSp3eVRZXate9iglOaKZMAkAYc7KZygjEAgKm82m5PgYqkwCQDfFHAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBlBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBlBAgAAGAZAQIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBlBAgAAGAZAQIAAFgWtABRWFioW2+9VUOGDFFcXJyGDRume+65RzU1NS0e9+mnn+r73/+++vTpo169emnWrFk6fvx4sLoJAADaIGgBYvfu3aqvr9fjjz+uHTt26He/+52WL1+uu+++u8XjfvzjH+uf//ynXnjhBa1fv17Hjh3TzJkzg9VNAADQBjZjjOmsb/bQQw/pscce08GDBwPudzqdSk1N1bPPPquvfvWrkhqCyIUXXqj8/HxNnDjxnN+joqJCiYmJcjqdSkhI6ND+AwDQnVn5DO3UORBOp1MpKSnN7i8oKJDH49H06dN920aOHKlBgwYpPz8/4DHV1dWqqKjwewAAgODqtACxf/9+/eEPf9B3vvOdZtuUlJQoJiZGSUlJftv79++vkpKSgMcsXbpUiYmJvkdGRkZHdrtbM8aorKpGR8pcKquqUScORgEAurgoqwfcddddevDBB1tss2vXLo0cOdL3/OjRo5oxY4ZuuukmzZ8/33ovW7Bo0SItXLjQ97yiooIQcQ5Ot0cvFhRr5cZCHS5z+bYPTnFoXnamZmWlKzEuOoQ9BACEO8sB4s4771ROTk6LbYYOHer797Fjx3TVVVcpOztbTzzxRIvHpaWlqaamRuXl5X6jEMePH1daWlrAY+x2u+x2e6v739Ot31uqBasK9HTO5ZqXnan71uz07Ssqc2nJmp1a9sYePTYnS1OGp4awpwCAcGY5QKSmpio1tXUfLEePHtVVV12lrKws5eXlKSKi5SsmWVlZio6O1tq1azVr1ixJ0p49e1RUVKRJkyZZ7SoaWb+3VLl5W9TchQrvdrenTrl5W5SXO54QAQAIKGhzII4ePaqpU6dq0KBBWrZsmUpLS1VSUuI3l+Ho0aMaOXKktmzZIklKTEzUrbfeqoULF+rtt99WQUGBcnNzNWnSpFbdgYHmOd0eLVhVICPpXFMdjGkIEwtWFcjp9nRG9wAAXYzlEYjWevPNN7V//37t379f6enpfvu8k/U8Ho/27Nkjl+uz6/C/+93vFBERoVmzZqm6ulrXXHON/vSnPwWrmz3GiwXFctfU+Y0+REbYdO+XL9JXxp2n2jqjVZsO6+E390pqCBHumjqt3las3MlDQtNpAEDY6tQ6EJ2BOhBNGWM09aF1Kipz+QLEc7dN1MXnJer5rUe0atNhjU5P1NKZo3XfP3fqua1HJEk2SYNSHFr306my2Wwh6z8AoHNY+QwN2ggEwscpl8fvbguvj8vdvkmUB09UaWRab916xRBfgDCSDpe5VO7yKDk+pjO7DAAIcyym1QNUVdcG3P7+kXK/59uKypXZN14RjQYbKps5HgDQcxEgeoB4e/sGmnq183gAQPdDgOgBkh3RGpziUONZDGMykvyej81IUuGJKtWfmShhU0NxqSQHRaUAAP4IED2AzWbTvOzMJtsHJsXp59dfqKF94/XlSwdqXnam8jYU+rXJmZzJBEoAQBOMTfcQs7LSteyNPXJ76nx1IFZvK1ZsdKRevn2y6uuN8jYU6tktRZKkCJsUGx2pmePSW/iqAICeits4e5CzK1G29KrbbA2XL1bkjteVVKIEgB4jbJfzRmhNGZ6qvNzxiouOlE1qMifCuy0uOpLwAABoEZcwepgpw1OVv2iaVm8r1ooN/qtxDkpxKGdyw2qcCbFMnAQANI9LGD2YMUblLo8qq2vVyx6lJEc0EyYBoAejEiVaxWazKTk+hiqTAADLmAMBAAAsI0AAAADLCBAAAMAyAgQAALCMAAEAACwjQAAAAMsIEAAAwDICBAAAsIwAAQAALCNAAAAAy7pdKWvv0h4VFRUh7gkAAF2L97OzNctkdbsAcfr0aUlSRkZGiHsCAEDXdPr0aSUmJrbYptutxllfX69jx46pd+/e3X5lyYqKCmVkZOjIkSM9auVRzpvz7gl64nn3xHOWwuu8jTE6ffq0Bg4cqIiIlmc5dLsRiIiICKWnp4e6G50qISEh5D90ocB59yycd8/RE89ZCp/zPtfIgxeTKAEAgGUECAAAYBkBoguz2+265557ZLfbQ92VTsV5c949QU887554zlLXPe9uN4kSAAAEHyMQAADAMgIEAACwjAABAAAsI0AAAADLCBAAAMAyAkQYu//++5WdnS2Hw6GkpKRWHWOM0eLFizVgwADFxcVp+vTp2rdvn1+bsrIyfeMb31BCQoKSkpJ06623qrKyMghn0DZW+1dYWCibzRbw8cILL/jaBdr/3HPPdcYptUpbXpepU6c2Oafvfve7fm2Kiop0/fXXy+FwqF+/fvrpT3+q2traYJ6KJVbPu6ysTD/4wQ80YsQIxcXFadCgQfrhD38op9Pp1y7cXu9HH31UmZmZio2N1YQJE7Rly5YW27/wwgsaOXKkYmNjNXr0aL366qt++1vzux4OrJz3k08+qc997nNKTk5WcnKypk+f3qR9Tk5Ok9d1xowZwT4Ny6yc94oVK5qcU2xsrF+bsHy9DcLW4sWLzcMPP2wWLlxoEhMTW3XMAw88YBITE83LL79sPvjgA/PlL3/ZDBkyxLjdbl+bGTNmmEsvvdRs2rTJvPPOO+b88883t9xyS5DOwjqr/autrTUff/yx3+Pee+81vXr1MqdPn/a1k2Ty8vL82p39/xJqbXldpkyZYubPn+93Tk6n07e/trbWXHzxxWb69Onm/fffN6+++qrp27evWbRoUbBPp9WsnvdHH31kZs6caV555RWzf/9+s3btWnPBBReYWbNm+bULp9f7ueeeMzExMebpp582O3bsMPPnzzdJSUnm+PHjAdtv2LDBREZGmt/85jdm586d5uc//7mJjo42H330ka9Na37XQ83qeX/96183jz76qHn//ffNrl27TE5OjklMTDTFxcW+NvPmzTMzZszwe13Lyso665Raxep55+XlmYSEBL9zKikp8WsTjq83AaILyMvLa1WAqK+vN2lpaeahhx7ybSsvLzd2u9389a9/NcYYs3PnTiPJbN261dfmtddeMzabzRw9erTD+25VR/VvzJgx5lvf+pbfNknmpZde6qiudqi2nveUKVPMj370o2b3v/rqqyYiIsLvzeixxx4zCQkJprq6ukP63h4d9Xo///zzJiYmxng8Ht+2cHq9x48fb77//e/7ntfV1ZmBAweapUuXBmz/ta99zVx//fV+2yZMmGC+853vGGNa97seDqyed2O1tbWmd+/eZuXKlb5t8+bNMzfccENHd7VDWT3vc73Hh+vrzSWMbuTQoUMqKSnR9OnTfdsSExM1YcIE5efnS5Ly8/OVlJSkyy67zNdm+vTpioiI0ObNmzu9z411RP8KCgq0fft23XrrrU32ff/731ffvn01fvx4Pf30061a874ztOe8n3nmGfXt21cXX3yxFi1aJJfL5fd1R48erf79+/u2XXPNNaqoqNCOHTs6/kQs6qifR6fTqYSEBEVF+a8PGA6vd01NjQoKCvx+LyMiIjR9+nTf72Vj+fn5fu2lhtfN2741v+uh1pbzbszlcsnj8SglJcVv+7p169SvXz+NGDFCCxYs0MmTJzu07+3R1vOurKzU4MGDlZGRoRtuuMHv9zNcX+9utxpnT1ZSUiJJfh8W3ufefSUlJerXr5/f/qioKKWkpPjahFJH9O+pp57ShRdeqOzsbL/t9913nz7/+c/L4XDojTfe0Pe+9z1VVlbqhz/8YYf1v63aet5f//rXNXjwYA0cOFAffvihfvazn2nPnj1avXq17+sG+nnw7gu1jni9T5w4oSVLlui2227z2x4ur/eJEydUV1cX8HXYvXt3wGOae93O/j32bmuuTai15bwb+9nPfqaBAwf6fXDOmDFDM2fO1JAhQ3TgwAHdfffduvbaa5Wfn6/IyMgOPYe2aMt5jxgxQk8//bQuueQSOZ1OLVu2TNnZ2dqxY4fS09PD9vUmQHSyu+66Sw8++GCLbXbt2qWRI0d2Uo86R2vPu73cbreeffZZ/eIXv2iy7+xtY8eOVVVVlR566KGgfqAE+7zP/tAcPXq0BgwYoGnTpunAgQMaNmxYm79ue3XW611RUaHrr79eo0aN0i9/+Uu/faF4vdFxHnjgAT333HNat26d34TC2bNn+/49evRoXXLJJRo2bJjWrVunadOmhaKr7TZp0iRNmjTJ9zw7O1sXXnihHn/8cS1ZsiSEPWsZAaKT3XnnncrJyWmxzdChQ9v0tdPS0iRJx48f14ABA3zbjx8/rjFjxvjafPLJJ37H1dbWqqyszHd8MLT2vNvbv7///e9yuVyaO3fuOdtOmDBBS5YsUXV1ddAWsems8/aaMGGCJGn//v0aNmyY0tLSmsz+Pn78uCR1+df79OnTmjFjhnr37q2XXnpJ0dHRLbbvjNc7kL59+yoyMtL3/+51/PjxZs8xLS2txfat+V0Ptbact9eyZcv0wAMP6K233tIll1zSYtuhQ4eqb9++2r9/f1gEiPact1d0dLTGjh2r/fv3Swrj1ztksy/QalYnUS5btsy3zel0BpxE+d577/na/Pvf/w67SZRt7d+UKVOazMZvzq9+9SuTnJzc5r52pI56Xd59910jyXzwwQfGmM8mUZ49+/vxxx83CQkJ5tNPP+24E2ijtp630+k0EydONFOmTDFVVVWt+l6hfL3Hjx9vbr/9dt/zuro6c95557U4ifKLX/yi37ZJkyY1mUTZ0u96OLB63sYY8+CDD5qEhASTn5/fqu9x5MgRY7PZzD/+8Y9297ejtOW8z1ZbW2tGjBhhfvzjHxtjwvf1JkCEscOHD5v333/fd0vi+++/b95//32/WxNHjBhhVq9e7Xv+wAMPmKSkJPOPf/zDfPjhh+aGG24IeBvn2LFjzebNm827775rLrjggrC7jbOl/hUXF5sRI0aYzZs3+x23b98+Y7PZzGuvvdbka77yyivmySefNB999JHZt2+f+dOf/mQcDodZvHhx0M+ntaye9/79+819991n3nvvPXPo0CHzj3/8wwwdOtRceeWVvmO8t3FeffXVZvv27eb11183qampYXcbp5XzdjqdZsKECWb06NFm//79fre+1dbWGmPC7/V+7rnnjN1uNytWrDA7d+40t912m0lKSvLdHfPNb37T3HXXXb72GzZsMFFRUWbZsmVm165d5p577gl4G+e5ftdDzep5P/DAAyYmJsb8/e9/93tdve95p0+fNj/5yU9Mfn6+OXTokHnrrbfMuHHjzAUXXBAWgdjL6nnfe++95t///rc5cOCAKSgoMLNnzzaxsbFmx44dvjbh+HoTIMLYvHnzjKQmj7ffftvXRmfudfeqr683v/jFL0z//v2N3W4306ZNM3v27PH7uidPnjS33HKL6dWrl0lISDC5ubl+oSTUztW/Q4cONfl/MMaYRYsWmYyMDFNXV9fka7722mtmzJgxplevXiY+Pt5ceumlZvny5QHbhorV8y4qKjJXXnmlSUlJMXa73Zx//vnmpz/9qV8dCGOMKSwsNNdee62Ji4szffv2NXfeeaff7Y6hZvW833777YC/F5LMoUOHjDHh+Xr/4Q9/MIMGDTIxMTFm/PjxZtOmTb59U6ZMMfPmzfNr//zzz5vhw4ebmJgYc9FFF5l//etffvtb87seDqyc9+DBgwO+rvfcc48xxhiXy2Wuvvpqk5qaaqKjo83gwYPN/Pnzm9RMCAdWzvuOO+7wte3fv7+57rrrzLZt2/y+Xji+3jZjwuQ+NgAA0GVQBwIAAFhGgAAAAJYRIAAAgGUECAAAYBkBAgAAWEaAAAAAlhEgAACAZQQIAABgGQECAABYRoAAAACWESAAAIBl/x/ZnreQh7zsbwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Visualise the Embeddings of our characters ###\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "#plot the dims of the embedding matrix\n",
    "plt.scatter(C[:, 0].data, C[:, 1].data, s=100)\n",
    "\n",
    "#iterate through and on the dot place the letter\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i, 0].item(), C[i, 1].item(), s=idx_to_char[i], ha=\"center\", va=\"center\", color=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intrestingly, the vowels are clustered together! The model assigns similarlity to these, meaning theyre interchangeable in a sense!\n",
    "There are the main cluster of letters in the center. \n",
    "there are q and . that are far away  aswell as b and f from the main cluster indicating that these are exceptional characters. Fasinating!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets play around with the hyper paramters to try and get a best model. Here we are doing this in a trail and error, unstructured way, but we'll learn about best practices soon. Lets just play for now!\n",
    "\n",
    "Hyperparameters:\n",
    "* Number of neurons in the linear layer\n",
    "* batch_size\n",
    "* number of dimensions in our embeddings\n",
    "* learning rate\n",
    "* context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Loss: 32.432\n",
      "Current Loss: 2.776\n",
      "Current Loss: 2.294\n",
      "Current Loss: 2.645\n",
      "Current Loss: 2.226\n",
      "Current Loss: 2.204\n",
      "Current Loss: 2.098\n",
      "Current Loss: 2.360\n",
      "Current Loss: 2.197\n",
      "Current Loss: 2.059\n"
     ]
    }
   ],
   "source": [
    "### Train network ###\n",
    "\n",
    "ll_neurons = 250\n",
    "mini_batch_size=64\n",
    "emb_dim = 10\n",
    "iterations = 100_000\n",
    "\n",
    "\n",
    "## Lets reverse the order, so going from large steps to small steps:\n",
    "## Parameters ##\n",
    "C = torch.randn((27, emb_dim))\n",
    "w1 = torch.randn((3*emb_dim, ll_neurons)) \n",
    "b1 = torch.randn((ll_neurons)) \n",
    "w2 = torch.randn((ll_neurons, 27)) \n",
    "b2 = torch.randn((27)) \n",
    "parameters = [C, w1, b1, w2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    " \n",
    "for i in range(iterations):\n",
    "\n",
    "   \n",
    "    ix = torch.randint(0, X_train.shape[0], (mini_batch_size,))\n",
    "\n",
    "    ## FORWARD PASS ##\n",
    "    emb = C[X_train[ix]] # (mini_batch_size, 3, emb_dim) <-- 3 is the context length\n",
    "    h1 = torch.tanh(emb.view(-1, 3*emb_dim) @ w1 + b1) #(mini_batch_size, context_len_x_emb_dim)x(context_len_x_emb_dim, ll_neurons) gives (mini_batch_size, ll_neurons)\n",
    "    logits = h1 @ w2 + b2 #(mini_batch_size, 27) <-- 27 is length of our vocab (we want to produce p(next_char over dist given the seq))\n",
    "    loss = F.cross_entropy(logits, Y_train[ix]) #softmax is applied internally\n",
    "\n",
    "    ## BACKWARDS PASS ##\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    ## UPDATE ##\n",
    "    if i <= 50_000:\n",
    "        lr=0.1\n",
    "    elif ((i>50_000) & (i<80_000)):\n",
    "        lr=0.01\n",
    "    else:\n",
    "        lr=0.001\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    if i % 10_000 == 0:\n",
    "        print(f\"Current Loss: {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 2.141\n"
     ]
    }
   ],
   "source": [
    "## Run Forward pss on training set to get training loss\n",
    "\n",
    "emb = C[X_train]\n",
    "h1 = torch.tanh(emb.view(-1, 3*emb_dim) @ w1 + b1) #<-- context_len=3\n",
    "logits = h1 @ w2 + b2 \n",
    "loss = F.cross_entropy(logits, Y_train)\n",
    "print(f\"training loss: {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 2.181\n"
     ]
    }
   ],
   "source": [
    "## Run forward pass on validation data to get validation loss\n",
    "emb = C[X_val]\n",
    "h1 = torch.tanh(emb.view(-1, 3*emb_dim) @ w1 + b1)\n",
    "logits = h1 @ w2 + b2 \n",
    "loss = F.cross_entropy(logits, Y_val)\n",
    "print(f\"Validation loss: {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the model\n",
    "\n",
    "The model is trained. it has adjusted its weights to best minimise the loss. Now it is time to generate new samples. Think lets pass one data point through the forward pass. Starting with context=\"...\" until we draw a \".\" to represent the end of our name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jacklin.\n",
      "sina.\n",
      "alicaily.\n",
      "barisemasa.\n",
      "azcetain.\n",
      "sathleey.\n",
      "lidiah.\n",
      "ect.\n",
      "max.\n",
      "hia.\n"
     ]
    }
   ],
   "source": [
    "generated_chars = []\n",
    "NUMBER_OF_NAMES = 10\n",
    "\n",
    "for _ in range(NUMBER_OF_NAMES):\n",
    "    #start with ...\n",
    "    context = [0] * 3\n",
    "    \n",
    "    while True:\n",
    "        #send it through the forward pass\n",
    "        emb = C[context] #(1_example, context_len, emb_dim) = (1, 3, 10)\n",
    "        h1 = torch.tanh(emb.view(-1, 3*emb_dim) @ w1 + b1) #(1, ll_neuron)\n",
    "        logits = h1 @ w2 + b2 #(1, 27) <-- 27 is length of our vocab \n",
    "\n",
    "        #now we create the prob dist (note: this was previously done internallu in cross_entorpy - but we dont want t he loss calculation, we want the prob dist)\n",
    "        prob_dist = F.softmax(logits, dim=1) #logits is a row vector, so calculate over the row (i.e. across dim 1 which the columns across the columns gives over the row)\n",
    "\n",
    "        #now we sample from the dist (a multinomal will do that for us)\n",
    "        idx = torch.multinomial(prob_dist, 1).item()\n",
    "        generated_chars.append(idx_to_char[idx])\n",
    "\n",
    "        if idx == 0:\n",
    "            break\n",
    "\n",
    "        context = context[1:] + [idx]\n",
    "\n",
    "    print(\"\".join(generated_chars))\n",
    "    generated_chars=[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
